{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치 기본 사용법\n",
    "\n",
    "pytorch의 기본 사용법을 tensor datatype부터 mnist 훈련까지 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1: 필요한 패키지 임포트\n",
    "\n",
    "현재 프로젝트에서 필요한 패키지를 임포트해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2: 파이토치 데이터타입\n",
    "\n",
    "### torch.Tensor\n",
    "파이토치의 기본 Array 자료형은 torch.Tensor이다.\n",
    "\n",
    "Tensor는 numpy의 array와 비슷하지만 GPU연산을 지원한다. Tensor의 데이터타입을 확인하고 싶으면 type(TensorData)를, Tensor의 shape을 확인하고 싶으면 TensorData.size()를 이용하면 된다.\n",
    "\n",
    "* 직접 Tensor 생성, torch.tensor()\n",
    "* 각 요소가 모두 0인 Tensor 생성, torch.zeros()\n",
    "* 각 요소가 모두 1인 Tensor 생성, torch.ones()\n",
    "* uniform distributed random Tensor 생성, torch.rand()\n",
    "* normal distributed random Tensor 생성, torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)\n",
    "print(type(x))\n",
    "y = torch.tensor([[1, 2],[3, 4]])\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.6084, 0.6943],\n",
      "        [0.1454, 0.8221]])\n",
      "tensor([[-1.2354, -0.3589],\n",
      "        [-0.8280, -0.4124]])\n"
     ]
    }
   ],
   "source": [
    "print(\"---------\")\n",
    "zero_tensor = torch.zeros(2, 2)\n",
    "print(zero_tensor)\n",
    "one_tensor = torch.ones(2, 2)\n",
    "print(one_tensor)\n",
    "random_tensor = torch.rand(2, 2)\n",
    "print(random_tensor)\n",
    "normal_tensor = torch.randn(2, 2)\n",
    "print(normal_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtype\n",
    "\n",
    "각 원소의 데이터 타입 또한 정의할 수 있다. 파이토치는 아래와 같은 데이터 타입들을 가지고 있다.\n",
    "\n",
    "* 64 bit floating point: torch.float64\n",
    "* 32 bit floating point: torch.float32\n",
    "* 16 bit floating point: torch.float16\n",
    "* 8 bit unsigned int: torch.uint8\n",
    "* 8 bit int: torch.int8\n",
    "* 16 bit int: torch.int16\n",
    "* 32 bit int: torch.int32\n",
    "* 64 bit int: torch.int64\n",
    "* boolean: torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4286, 0.5000, 0.5556, 0.6000])\n",
      "tensor([0, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x_real = torch.tensor([3, 4, 5, 6], dtype=torch.float32)\n",
    "y_real = torch.tensor([7, 8, 9, 10], dtype=torch.float32)\n",
    "x_int = torch.tensor([3, 4, 5, 6], dtype=torch.int32)\n",
    "y_int = torch.tensor([7, 8, 9, 10], dtype=torch.int32)\n",
    "\n",
    "print(x_real / y_real)\n",
    "print(x_int / y_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 3. 사칙연산\n",
    "\n",
    "사칙연산은 넘파이와 동일하게 +, -, *, /연산자로 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 5.],\n",
      "        [7., 9.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[ 2.,  6.],\n",
      "        [12., 20.]])\n",
      "tensor([[0.5000, 0.6667],\n",
      "        [0.7500, 0.8000]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
    "x2 = torch.tensor([[2.0, 3.0],[4.0, 5.0]])\n",
    "print(x1 + x2)\n",
    "print(x1 - x2)\n",
    "print(x1 * x2)\n",
    "print(x1 / x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor.view(): Array reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(x)\n",
    "print(x.size())\n",
    "y = x.view(1, -1)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50])\n",
      "torch.Size([10, 20])\n",
      "tensor([0.6073, 0.6094, 0.5311,  ..., 0.5972, 0.6418, 0.6579])\n",
      "torch.Size([1267])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(50, 50)\n",
    "print(x.size())\n",
    "\n",
    "y = x[0:10, 20:40]\n",
    "print(y.size())\n",
    "\n",
    "z = x[x > 0.5]\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[ 0.2323, -0.2769],\n",
      "        [-0.2474,  0.4452]])\n",
      "[[ 0.23233348 -0.27687767]\n",
      " [-0.24738401  0.44523707]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "b = a.numpy()\n",
    "print(type(a))\n",
    "print(type(b))\n",
    "a.div_(3)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "c = np.array([[2., 4.],[6., 8.]])\n",
    "d = torch.from_numpy(c)\n",
    "print(type(c))\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "True\n",
      "<AddBackward0 object at 0x000001CC8DE0E080>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch로 CNN을 이용하여 MNIST 훈련\n",
    "\n",
    "Nvidia GPU를 이용하여 CNN 네트워크를 훈련시켜 99% 이상 정확도 달성\n",
    "\n",
    "## step 1. 데이터 불러오기\n",
    "\n",
    "torchvision.datasets 모듈에서 편리하게 mnist 데이터를 가져올 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. torchvision 모듈의 datasets 기능을 이용하여 MNIST 데이터셋을 불러온다.\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# 이미지를 불러올 때 Tensor형태로(원형 = PIL image), mean = 0.5, std = 1.0으로 정규화하여 저장\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "# MNIST 데이터셋 불러오기\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=trans)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=trans)\n",
    "\n",
    "# *** 추가로 알아봐야 할 부분: datasets에서 가져오는 데이터 말고 다른 데이터를 가져오는 방법 *** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번에 훈련할 미니배치 사이즈\n",
    "batch_size = 1024\n",
    "# GPU시스템인지 확인\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "#dataloader 정의\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=mnist_trainset,\n",
    "                 batch_size=batch_size,\n",
    "                 num_workers=4,\n",
    "                 pin_memory=True,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=mnist_testset,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=4,\n",
    "                pin_memory=True,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "훈련할 neural network 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"My first CNN with pyTorch!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet()\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0, loss: 39.192721858620644\n",
      "1\n",
      "epoch 1, loss: 7.963860556483269\n",
      "2\n",
      "epoch 2, loss: 4.854638423770666\n",
      "3\n",
      "epoch 3, loss: 3.6931767985224724\n",
      "4\n",
      "epoch 4, loss: 3.0206321086734533\n",
      "5\n",
      "epoch 5, loss: 2.4738875962793827\n",
      "6\n",
      "epoch 6, loss: 2.0958620626479387\n",
      "7\n",
      "epoch 7, loss: 1.7452487237751484\n",
      "8\n",
      "epoch 8, loss: 1.564565814100206\n",
      "9\n",
      "epoch 9, loss: 1.324633021838963\n",
      "Finished Training\n",
      "소요 시간 : 54.881710052490234\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "    print(epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = model.forward(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'epoch {epoch}, loss: {running_loss}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "compute_t = time.time() - start\n",
    "print(f'소요 시간 : {compute_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test accuracy\n",
      "0.9907\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for testdata in test_loader:\n",
    "    data, target = testdata\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    output = model.forward(data)\n",
    "    _, pred = torch.max(output.data, 1)\n",
    "    total += target.size(0)\n",
    "    correct += (pred == target).sum()\n",
    "    \n",
    "print(\"model test accuracy\")\n",
    "acc = correct.item() / total\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0, loss: 13.802269220352173\n",
      "1\n",
      "epoch 1, loss: 13.764296531677246\n",
      "2\n",
      "epoch 2, loss: 13.705218315124512\n",
      "3\n",
      "epoch 3, loss: 13.629156589508057\n",
      "4\n",
      "epoch 4, loss: 13.5269296169281\n",
      "5\n",
      "epoch 5, loss: 13.382502317428589\n",
      "6\n",
      "epoch 6, loss: 13.165460348129272\n",
      "7\n",
      "epoch 7, loss: 12.821048498153687\n",
      "8\n",
      "epoch 8, loss: 12.241288304328918\n",
      "9\n",
      "epoch 9, loss: 11.231246590614319\n",
      "Finished Training\n",
      "소요 시간 : 407.9290964603424\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "    print(epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = model.forward(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'epoch {epoch}, loss: {running_loss}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "compute_t = time.time() - start\n",
    "print(f'소요 시간 : {compute_t}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
